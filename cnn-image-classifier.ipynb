{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f1205e",
   "metadata": {
    "papermill": {
     "duration": 0.009866,
     "end_time": "2023-08-25T21:50:43.545197",
     "exception": false,
     "start_time": "2023-08-25T21:50:43.535331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>[Histopathologic Cancer Detection](https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview)</center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba83c01",
   "metadata": {
    "papermill": {
     "duration": 0.009306,
     "end_time": "2023-08-25T21:50:43.563715",
     "exception": false,
     "start_time": "2023-08-25T21:50:43.554409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## [About the data](https://www.kaggle.com/competitions/histopathologic-cancer-detection/data)\n",
    "In this dataset, you are provided with a large number of small pathology images to classify. Files are named with an image **`id`**. The **`train_labels.csv`** file provides the ground truth for the images in the **`train`** folder. You are predicting the labels for the images in the **`test`** folder. A **`positive label`** indicates that the center **`32x32px`** region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.\n",
    "\n",
    "The original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8eca25",
   "metadata": {
    "papermill": {
     "duration": 0.009281,
     "end_time": "2023-08-25T21:50:43.582221",
     "exception": false,
     "start_time": "2023-08-25T21:50:43.572940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfc6611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:50:43.604238Z",
     "iopub.status.busy": "2023-08-25T21:50:43.603329Z",
     "iopub.status.idle": "2023-08-25T21:51:05.267612Z",
     "shell.execute_reply": "2023-08-25T21:51:05.266429Z"
    },
    "papermill": {
     "duration": 21.679738,
     "end_time": "2023-08-25T21:51:05.270881",
     "exception": false,
     "start_time": "2023-08-25T21:50:43.591143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics.functional import accuracy\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fa2605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:05.293501Z",
     "iopub.status.busy": "2023-08-25T21:51:05.292715Z",
     "iopub.status.idle": "2023-08-25T21:51:05.300386Z",
     "shell.execute_reply": "2023-08-25T21:51:05.299042Z"
    },
    "papermill": {
     "duration": 0.0212,
     "end_time": "2023-08-25T21:51:05.302968",
     "exception": false,
     "start_time": "2023-08-25T21:51:05.281768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.5.3\n",
      "numpy version: 1.23.5\n",
      "torch version: 2.0.0+cpu\n",
      "pytorch ligthening version: 2.0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"pandas version:\",pd.__version__)\n",
    "print(\"numpy version:\",np.__version__)\n",
    "#print(\"seaborn version:\",sns.__version__)\n",
    "print(\"torch version:\",torch.__version__)\n",
    "print(\"pytorch ligthening version:\",pl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed16146",
   "metadata": {
    "papermill": {
     "duration": 0.009149,
     "end_time": "2023-08-25T21:51:05.322015",
     "exception": false,
     "start_time": "2023-08-25T21:51:05.312866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Collecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f3dbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:05.344265Z",
     "iopub.status.busy": "2023-08-25T21:51:05.343837Z",
     "iopub.status.idle": "2023-08-25T21:51:42.929393Z",
     "shell.execute_reply": "2023-08-25T21:51:42.927768Z"
    },
    "papermill": {
     "duration": 37.60074,
     "end_time": "2023-08-25T21:51:42.932682",
     "exception": false,
     "start_time": "2023-08-25T21:51:05.331942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/kaggle\u001b[00m\r\n",
      "├── \u001b[01;34minput\u001b[00m\r\n",
      "│   └── \u001b[01;34mhistopathologic-cancer-detection\u001b[00m\r\n",
      "│       ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│       └── \u001b[01;34mtrain\u001b[00m\r\n",
      "├── \u001b[01;34mlib\u001b[00m\r\n",
      "│   └── \u001b[01;34mkaggle\u001b[00m\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "└── \u001b[01;34mworking\u001b[00m\r\n",
      "\r\n",
      "8 directories\r\n"
     ]
    }
   ],
   "source": [
    "! tree -d /kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19065a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:42.956632Z",
     "iopub.status.busy": "2023-08-25T21:51:42.956062Z",
     "iopub.status.idle": "2023-08-25T21:51:44.087778Z",
     "shell.execute_reply": "2023-08-25T21:51:44.086315Z"
    },
    "papermill": {
     "duration": 1.147672,
     "end_time": "2023-08-25T21:51:44.090771",
     "exception": false,
     "start_time": "2023-08-25T21:51:42.943099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,label\r\n",
      "f38a6374c348f90b587e046aac6079959adf3835,0\r\n",
      "c18f2d887b7ae4f6742ee445113fa1aef383ed77,1\r\n",
      "755db6279dae599ebb4d39a9123cce439965282d,0\r\n",
      "bc3f0c64fb968ff4a8bd33af6971ecae77c75e08,0\r\n",
      "068aba587a4950175d04c680d38943fd488d6a9d,0\r\n",
      "acfe80838488fae3c89bd21ade75be5c34e66be7,0\r\n",
      "a24ce148f6ffa7ef8eefb4efb12ebffe8dd700da,1\r\n",
      "7f6ccae485af121e0b6ee733022e226ee6b0c65f,1\r\n",
      "559e55a64c9ba828f700e948f6886f4cea919261,0\r\n"
     ]
    }
   ],
   "source": [
    "! head /kaggle/input/histopathologic-cancer-detection/train_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b15bff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:44.115079Z",
     "iopub.status.busy": "2023-08-25T21:51:44.114434Z",
     "iopub.status.idle": "2023-08-25T21:51:44.787143Z",
     "shell.execute_reply": "2023-08-25T21:51:44.785473Z"
    },
    "papermill": {
     "duration": 0.688717,
     "end_time": "2023-08-25T21:51:44.790109",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.101392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(filepath_or_buffer=\"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f190f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:44.812779Z",
     "iopub.status.busy": "2023-08-25T21:51:44.812289Z",
     "iopub.status.idle": "2023-08-25T21:51:44.821822Z",
     "shell.execute_reply": "2023-08-25T21:51:44.819241Z"
    },
    "papermill": {
     "duration": 0.025238,
     "end_time": "2023-08-25T21:51:44.825603",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.800365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220025, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6fe3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:44.849561Z",
     "iopub.status.busy": "2023-08-25T21:51:44.849137Z",
     "iopub.status.idle": "2023-08-25T21:51:44.877345Z",
     "shell.execute_reply": "2023-08-25T21:51:44.876337Z"
    },
    "papermill": {
     "duration": 0.044323,
     "end_time": "2023-08-25T21:51:44.881632",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.837309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    130908\n",
      "1     89117\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    59.496875\n",
       "1    40.503125\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target feature value_counts\n",
    "print(data_df[\"label\"].value_counts())\n",
    "data_df[\"label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28484b",
   "metadata": {
    "papermill": {
     "duration": 0.012774,
     "end_time": "2023-08-25T21:51:44.905164",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.892390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Since, the target feature i.e `label` has only two unique values i.e `[0,1]`, hence, it's a **`Binary Classification`** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9177c84",
   "metadata": {
    "papermill": {
     "duration": 0.010437,
     "end_time": "2023-08-25T21:51:44.926933",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.916496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Downsampling the dataset\n",
    "A positive label indicates that the center 32x32 px region of a patch contains at least one px of tumor tissue. There are **130,908 normal cases (0)** and **89,117 abnormal (or cancerous) tissue images (1)**. This is a huge dataset that will require a lot of time and compute resources to train on a full dataset, thus we will downsample the 220,000 images in the train folder to 10,000 images and then split them into training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d380fd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:44.951342Z",
     "iopub.status.busy": "2023-08-25T21:51:44.950883Z",
     "iopub.status.idle": "2023-08-25T21:51:45.362086Z",
     "shell.execute_reply": "2023-08-25T21:51:45.360974Z"
    },
    "papermill": {
     "duration": 0.427162,
     "end_time": "2023-08-25T21:51:45.364871",
     "exception": false,
     "start_time": "2023-08-25T21:51:44.937709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "train_imgs_orig = os.listdir(\"/kaggle/input/histopathologic-cancer-detection/train\")\n",
    "selected_image_list = []\n",
    "\n",
    "for img in np.random.choice(train_imgs_orig, 10000):\n",
    "    selected_image_list.append(img)\n",
    "    \n",
    "len(selected_image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a36206",
   "metadata": {
    "papermill": {
     "duration": 0.010802,
     "end_time": "2023-08-25T21:51:45.386344",
     "exception": false,
     "start_time": "2023-08-25T21:51:45.375542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2b37a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:45.410623Z",
     "iopub.status.busy": "2023-08-25T21:51:45.410246Z",
     "iopub.status.idle": "2023-08-25T21:51:45.418038Z",
     "shell.execute_reply": "2023-08-25T21:51:45.416732Z"
    },
    "papermill": {
     "duration": 0.023939,
     "end_time": "2023-08-25T21:51:45.421076",
     "exception": false,
     "start_time": "2023-08-25T21:51:45.397137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the downsampled training dataset: 8000\n",
      "Number of images in the downsampled testing dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(selected_image_list)\n",
    "\n",
    "train_idx = selected_image_list[:8000]\n",
    "test_idx = selected_image_list[8000:]\n",
    "\n",
    "print(f\"Number of images in the downsampled training dataset: {len(train_idx)}\")\n",
    "print(f\"Number of images in the downsampled testing dataset: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96244462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:51:45.445944Z",
     "iopub.status.busy": "2023-08-25T21:51:45.445493Z",
     "iopub.status.idle": "2023-08-25T21:52:35.015792Z",
     "shell.execute_reply": "2023-08-25T21:52:35.014303Z"
    },
    "papermill": {
     "duration": 49.597498,
     "end_time": "2023-08-25T21:52:35.029597",
     "exception": false,
     "start_time": "2023-08-25T21:51:45.432099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying of data from Source to Destination is completed!!!\n"
     ]
    }
   ],
   "source": [
    "### downsampled_train_dataset\n",
    "os.mkdir('/kaggle/working/downsampled_train_dataset')\n",
    "\n",
    "for file_name in train_idx:\n",
    "    source = os.path.join('/kaggle/input/histopathologic-cancer-detection/train',file_name)\n",
    "    destination = os.path.join('/kaggle/working/downsampled_train_dataset/', file_name)\n",
    "    shutil.copyfile(source, destination)\n",
    "\n",
    "### downsampled_test_dataset\n",
    "os.mkdir('/kaggle/working/downsampled_test_dataset')\n",
    "\n",
    "for file_name in test_idx:\n",
    "    # we used the train datset instead. of test because we are using the train datset itself for both training & testing\n",
    "    source = os.path.join('/kaggle/input/histopathologic-cancer-detection/train',file_name)\n",
    "    destination = os.path.join('/kaggle/working/downsampled_test_dataset/', file_name)\n",
    "    shutil.copyfile(source, destination)\n",
    "    \n",
    "print(\"Copying of data from Source to Destination is completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d1c7a",
   "metadata": {
    "papermill": {
     "duration": 0.012455,
     "end_time": "2023-08-25T21:52:35.053070",
     "exception": false,
     "start_time": "2023-08-25T21:52:35.040615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the preceding code snippet, we are first creating two folders called **`downsampled_train_dataset * downsampled_test_dataset`** on the following path:\n",
    "```python\n",
    "os.mkdir('/kaggle/working/downsampled_train_dataset')\n",
    "os.mkdir('/kaggle/working/downsampled_test_dataset')\n",
    "```\n",
    "Then, we are looping over `train_idx` to get image names for the training data and copying all the files from input storage in the machine allotted to us at the time we created a notebook to working storage on our Kaggle using the **shutils** Python module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225186f2",
   "metadata": {
    "papermill": {
     "duration": 0.011179,
     "end_time": "2023-08-25T21:52:35.075318",
     "exception": false,
     "start_time": "2023-08-25T21:52:35.064139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Label extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77dba4",
   "metadata": {
    "papermill": {
     "duration": 0.011006,
     "end_time": "2023-08-25T21:52:35.098402",
     "exception": false,
     "start_time": "2023-08-25T21:52:35.087396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The labels for the images that were selected in the downsampled data will be extracted in a list that will be used for training and evaluating the image classification model, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ee7b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:52:35.124036Z",
     "iopub.status.busy": "2023-08-25T21:52:35.123009Z",
     "iopub.status.idle": "2023-08-25T21:59:33.782423Z",
     "shell.execute_reply": "2023-08-25T21:59:33.780990Z"
    },
    "papermill": {
     "duration": 418.685682,
     "end_time": "2023-08-25T21:59:33.795433",
     "exception": false,
     "start_time": "2023-08-25T21:52:35.109751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['56a2b15a4da049186b939e872086a08c0b6406d6', 'bb64f942aafd122e8247a1bc057735f35877e6a6', '346e45de7df976a890dcd46115e90befd753bf55', 'fc92ba278f306c1d34f7f783ee5c0740a6541b5d', 'cff1f67703a6dcbc55983e1ecfa0f60d6294c1ef']\n",
      "[0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "selected_image_labels = pd.DataFrame()\n",
    "\n",
    "id_list = []\n",
    "label_list = []\n",
    "\n",
    "for img in selected_image_list:\n",
    "    label_tuple = data_df.loc[data_df['id'] == img.split('.')[0]]\n",
    "    id_list.append(label_tuple['id'].values[0])\n",
    "    label_list.append(label_tuple['label'].values[0])  \n",
    "    \n",
    "print(id_list[:5])\n",
    "print(label_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596c49c",
   "metadata": {
    "papermill": {
     "duration": 0.010479,
     "end_time": "2023-08-25T21:59:33.817039",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.806560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the dataset\n",
    "**PyTorch Lightning** `expects data to be in folders with the classes.` So, we cannot use the DataLoader module directly when all train/test images are in one folder without subfolders. Therefore, we will write our custom class for loading the data, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46facbd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:59:33.840945Z",
     "iopub.status.busy": "2023-08-25T21:59:33.840497Z",
     "iopub.status.idle": "2023-08-25T21:59:33.852246Z",
     "shell.execute_reply": "2023-08-25T21:59:33.850918Z"
    },
    "papermill": {
     "duration": 0.02711,
     "end_time": "2023-08-25T21:59:33.855192",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.828082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoadCancerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_folder, transform = T.Compose([T.CenterCrop(32),T.ToTensor()]), dict_labels={}):\n",
    "        self.data_folder = data_folder\n",
    "        self.list_image_files = [s for s in os.listdir(data_folder)]\n",
    "        self.transform = transform\n",
    "        self.dict_labels = dict_labels\n",
    "        self.labels = [dict_labels[i.split('.')[0]] for i in self.list_image_files]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_folder, self.list_image_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)[0]\n",
    "        img_name_short = self.list_image_files[idx].split('.')\n",
    "        label = self.dict_labels[img_name_short]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1911dfb",
   "metadata": {
    "papermill": {
     "duration": 0.010418,
     "end_time": "2023-08-25T21:59:33.876395",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.865977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the preceding code block, we have defined a custom data loader.\n",
    "\n",
    "The custom class defined earlier inherits from the `torch.utils.data.Dataset` module. The **LoadCancerDataset** custom class is initialized in the **__init__** method and accepts three arguments: **the `path to the data folder`, the `transformer` with a default value of cropping the image to size 32 and transforming it to a tensor, and a `dictionary` with the labels and IDs of the dataset.**\n",
    "\n",
    "The **LoadCancerDataset** class reads all the images in the folder and **extracts** the image name from the filename, which is also the `ID` for the images. This image name is then matched with the label in the dictionary with the labels and IDs.\n",
    "\n",
    "The **LoadCancerDataset** class returns the images and their labels, which can then be used in the DataLoader module of the `torch.utils.data` library as it can now read the images with their corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596af069",
   "metadata": {
    "papermill": {
     "duration": 0.011085,
     "end_time": "2023-08-25T21:59:33.898281",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.887196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Augmenting the dataset\n",
    "Now that we have loaded the data, we will start the process of data preprocessing by augmenting the images, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db099014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:59:33.921843Z",
     "iopub.status.busy": "2023-08-25T21:59:33.921400Z",
     "iopub.status.idle": "2023-08-25T21:59:33.927728Z",
     "shell.execute_reply": "2023-08-25T21:59:33.926862Z"
    },
    "papermill": {
     "duration": 0.020768,
     "end_time": "2023-08-25T21:59:33.929876",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.909108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_T_train = T.Compose([ T.CenterCrop(32), T.RandomHorizontalFlip(), T.RandomVerticalFlip(), T.ToTensor(), ])\n",
    "\n",
    "data_T_test = T.Compose([ T.CenterCrop(32), T.ToTensor(), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d00c9",
   "metadata": {
    "papermill": {
     "duration": 0.011428,
     "end_time": "2023-08-25T21:59:33.952742",
     "exception": false,
     "start_time": "2023-08-25T21:59:33.941314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the preceding code block,\n",
    "\n",
    "We have used transformations to crop the image to 32x32 by using **Torchvision's** built-in libraries. We then also **augmented the data** by flipping it horizontally and vertically, **thereby creating two additional copies from the original image.**\n",
    "\n",
    "Now, we will call our **LoadCancerDataset** custom class with the path to the data folder, transformer, and the image label dictionary to convert it to the format accepted by the `torch.utils.data.DataLoader` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f836196e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:59:33.979141Z",
     "iopub.status.busy": "2023-08-25T21:59:33.977891Z",
     "iopub.status.idle": "2023-08-25T21:59:35.249371Z",
     "shell.execute_reply": "2023-08-25T21:59:35.247183Z"
    },
    "papermill": {
     "duration": 1.287852,
     "end_time": "2023-08-25T21:59:35.252239",
     "exception": true,
     "start_time": "2023-08-25T21:59:33.964387",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train_set = LoadCancerDataset(data_folder=<span style=\"color: #808000; text-decoration-color: #808000\">'/kaggle/working/downsampled_train_dataset'</span>,tr     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>test_set = LoadCancerDataset(data_folder=<span style=\"color: #808000; text-decoration-color: #808000\">'/kaggle/working/downsampled_test_dataset'</span>,tran     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files = [s <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> s <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.listdir(data_folder)]                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transform = transform                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dict_labels = dict_labels                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.labels = [dict_labels[i.split(<span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files]         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__len__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files = [s <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> s <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.listdir(data_folder)]                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transform = transform                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dict_labels = dict_labels                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.labels = [dict_labels[i.split(<span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files]         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__len__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.list_image_files)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'7cd369c04a37c9da20bbfe1bcba2cfad754fc100'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train_set = LoadCancerDataset(data_folder=\u001b[33m'\u001b[0m\u001b[33m/kaggle/working/downsampled_train_dataset\u001b[0m\u001b[33m'\u001b[0m,tr     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mtest_set = LoadCancerDataset(data_folder=\u001b[33m'\u001b[0m\u001b[33m/kaggle/working/downsampled_test_dataset\u001b[0m\u001b[33m'\u001b[0m,tran     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m8\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.list_image_files = [s \u001b[94mfor\u001b[0m s \u001b[95min\u001b[0m os.listdir(data_folder)]                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.transform = transform                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.dict_labels = dict_labels                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.labels = [dict_labels[i.split(\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m)[\u001b[94m0\u001b[0m]] \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.list_image_files]         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__len__\u001b[0m(\u001b[96mself\u001b[0m):                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.list_image_files)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<listcomp>\u001b[0m:\u001b[94m8\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.list_image_files = [s \u001b[94mfor\u001b[0m s \u001b[95min\u001b[0m os.listdir(data_folder)]                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.transform = transform                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.dict_labels = dict_labels                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.labels = [dict_labels[i.split(\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m)[\u001b[94m0\u001b[0m]] \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.list_image_files]         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__len__\u001b[0m(\u001b[96mself\u001b[0m):                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.list_image_files)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'7cd369c04a37c9da20bbfe1bcba2cfad754fc100'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = LoadCancerDataset(data_folder='/kaggle/working/downsampled_train_dataset',transform=data_T_train,dict_labels={})\n",
    "test_set = LoadCancerDataset(data_folder='/kaggle/working/downsampled_test_dataset',transform=data_T_test,dict_labels={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d940e0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "This will be repeated for the test data as well, and then, in the final step, we will create train_dataloader and test_dataloader data loaders using the output from our LoadCancerDataset custom class by leveraging the DataLoader module from the torch.utils.data library. The code to do so is illustrated in the following snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa240b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T21:45:04.142701Z",
     "iopub.status.busy": "2023-08-25T21:45:04.142193Z",
     "iopub.status.idle": "2023-08-25T21:45:04.212092Z",
     "shell.execute_reply": "2023-08-25T21:45:04.210450Z",
     "shell.execute_reply.started": "2023-08-25T21:45:04.142655Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size, num_workers=2, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ebc67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "In the preceding code snippet, we have the following:\n",
    "1. We started with the original data without the subfolders as expected by the PyTorch Lightning module. The data was downsampled and saved on Google Drive's persistent storage.\n",
    "2. Using the LoadCancerDataset custom class, we created two datasets train_ set and test_set, by reading images and their labels.\n",
    "3. In the process of creating datasets, we also used the Torchvision transform module to crop the images to the center, that is, converting images to the square of 32 x 32 px and also converting images to tensors.\n",
    "4. In the final step, the two train_set and test_set datasets that were created are used to create two train_dataloader and test_dataloader data loaders for them.\n",
    "\n",
    "At this point, we are ready with our train_dataloader data loader with around 8,000 images, and test_dataloader with around 2,000 images. All the images are of size 32 x 32, converted to tensor form, and served in batches of 256 images. We will use the train data loader to train our model and the test data loader to measure our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd119c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 548.121994,
   "end_time": "2023-08-25T21:59:38.591317",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-25T21:50:30.469323",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
